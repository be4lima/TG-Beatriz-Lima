[["index.html", "Ciência de dados na Engenharia Ambiental e Urbana: abordagem introdutória com aplicações Sobre", " Ciência de dados na Engenharia Ambiental e Urbana: abordagem introdutória com aplicações Beatriz Morais Lima e Wallace Gusmão Ferreira 2022-06-21 Sobre Livro relacionado a técnicas de programação e modelagem de temas específicos da Engenharia Ambiental e Urbana. Será realizado um conjunto de materiais teóricos, equacionamentos, fluxo de dados e principais análises numéricas e gráficas. Além da elaboração de estudos de casos e tutoriais didáticos relacionados a esses tópicos da Engenharia Ambiental e Urbana. "],["r---introdução-e-comandos-básicos.html", "Capítulo 1 R - Introdução e Comandos Básicos 1.1 Definindo um diretório de trabalho 1.2 Vetores 1.3 Base de dados 1.4 Seleção de variáveis 1.5 R packages", " Capítulo 1 R - Introdução e Comandos Básicos R é uma linguagem e ambiente para computação estatística e gráficos. Essa linguagem de programação fornece uma grande variedade de técnicas estatísticas (modelagem linear e não-linear, testes estatísticos clássicos, análise de séries temporais, etc) e gráficas (The R Foundation, 2022). 1.1 Definindo um diretório de trabalho O diretório de trabalho é o local onde a base de dados de um projeto está salva. Para verificar qual é o diretório de trabalho atual, basta utilizar a função getwd(). getwd() Para definir um novo diretório de trabalho, basta utilizar a função setwd() e inserir como argumento o caminho desejado, conforme exemplo abaixo. setwd(&quot;Home/Beatriz/documentos/Data Science&quot;) 1.2 Vetores Vetores permitem que sejam armazenados conjuntos de valores sob um mesmo nome. Serão apresentadas três maneiras de criar vetores abaixo. Utilizando a função c(v1, v2, v3,..., vi) que concatena os valores presentes no argumento e cria um vetor; &gt; Valores &lt;- c(1,2,3,4,5) Utilizando o comando seq(from,to, by, length) que gera sequências números de um valor inicial (from) até um valor final (to) com um incremento (by) e um comprimento (length). Exemplo 1: seq (from, to, by) &gt; Valores &lt;- seq(1,6,by=1) [1] 1.0 3.0 3.0 4.0 5.0 6.0 Exemplo 2: seq (from, to, length) &gt; Valores &lt;- seq(2,10,length=5) [1] 2 4 6 8 10 Exemplo 3: seq (from, to, length) &gt; Valores &lt;- seq(from=2,by=10,length=6) [1] 2 12 22 32 42 52 Utilizando o comando from:to que cria a sequência de um valor inicial (from) até um final (to) com o incremento de by=1. Exemplo: &gt; Valores &lt;- 1:10 [1] 1 2 3 4 5 6 7 8 9 10 1.3 Base de dados Para realizar a leitura de uma base de dados, basta utilizar a função read(). Exemplos de formatos de arquivo são .csv, .txt, .xlsx, entre outros. A forma mais comum de disponibilização de dados é o formato .csv e a leitura dessa base de dados pode ser realizada conforme demonstrado abaixo. dados &lt;- read.csv(\"Data Science/dados.csv\") Note que o caminho escrito está pela metade, pois o diretório de trabalho já foi definido. Dessa forma, não é necessário escrever o caminho inteiro do arquivo dados.csv, por já estar localizado no diretório. Para exploração dos dados, inicialmente algumas funções são úteis: View() para visualização dos dados .csv em uma tabela; Names() para exibição dos nomes das variáveis presentes na base de dados; Summary() para a realização de um sumário de estatísticas para as variáveis numéricas da base de dados (mínimo, máximo, mediana, média, 1º quartil, 3º quartil e número de NAs). 1.4 Seleção de variáveis Para realizar a análise dos dados, é necessário selecionar variáveis do banco de dados e filtrar seus valores. Ou seja, é necessário criar subconjuntos. Em R, estes podem ser criados com o uso de colchetes: dados[observações,variáveis]. Por exemplo, para um conjunto de dados com numerações para cada uma das observações, se desejamos selecionar as 4 primeiras observações, basta realizar o comando dados[1:4,]. 1.5 R packages Um R package é um conjunto de funções que extendem a capacidade da base R. Na análise exploratória de dados, um pacote importante para a organização dos dados é o tidyverse(); para visualizações, o ggplot2(); e, para gráficos de correlação, corrplot(). Para o instalar, basta escrever a seguinte linha de código, inserindo no argumento o nome do pacote: install.packages(&quot;tidyverse&quot;) Após instalar um pacote, é necessário carregá-lo para poder utilizar todas as suas funcionalidades. Portanto, basta utilizar a função library() para instalar, inserindo o nome do pacote como argumento. Nesse caso, não utiliza-se aspas no argumento. "],["análise-exploratória-de-dados.html", "Capítulo 2 Análise Exploratória de Dados 2.1 População e amostra 2.2 Sumarização numérica de dados Aplicação", " Capítulo 2 Análise Exploratória de Dados A Análise Exploratória de Dados (EDA) é uma forma de utilizar ferramentas gráficas e estatísticas apropriadas da linguagem R na exploração de dados. A partir da visualização, transformação e modelagem de dados, essa análise explora os dados de forma sistemática (WICKHMAN &amp; GROLEMUND, 2017). Para aplicar a EDA, de acordo com Wickhman &amp; Grolemund (2017), basta inicialmente gerar questões sobre os dados, utilizar as funcionalidades do R para encontrar respostas e utilizar o que foi aprendido para gerar novas questões. Portanto, essa análise é um ciclo iterativo. 2.1 População e amostra A População é um conjunto de observações relacionadas a indivíduos com uma característica em comum. Já a Amostra é um subconjunto da população, com uma parte das observações relacionadas à população. A partir da amostra realizam-se inferências sobre as características da população. É importante que a amostra seja representativa para que os resultados não sejam deturpados. 2.2 Sumarização numérica de dados Resumos numéricos de dados são fundamentais para realizar inferências estatísticas, porque, de acordo com Montgomery &amp; Runger (2021), permitem ao engenheiro focar nas características importantes dos dados ou ter discernimento acerca do tipo de modelo que deveria ser usado na solução do problema. Por isso, torna-se útil descrever numericamente, a partir de medidas de posição, variabilidade e forma, características dos dados. 2.2.1 Medidas de Posição 2.2.1.1 Média A média é a divisão da soma de todos os valores da série pelo número de obervações n. \\(\\bar{x}=\\frac{x_{1}+x_{2}+x_{3}...x_{n}}{n}=\\frac{\\sum x_n}{n}\\) 2.2.1.2 Mediana Em um conjunto de valores ordenados, a mediana é o valor que ocupa a posição central. Portanto, a mediana divide a distribuição de valores na metade. 2.2.1.3 Moda Em um conjunto de valores, a Moda seria o valor que ocorre com maior frequência. Ou seja, o valor que mais se repete. 2.2.2 Medidas de Variabilidade 2.2.2.1 Amplitude Em um conjunto de observações, a Amplitude é a diferença entre o maior valor e o menor. 2.2.2.2 Variância Para uma amostra de n observações, a Variância será: \\(s=\\frac{\\sum(x_{i}-\\bar{x})^{2}}{n-1}\\) 2.2.2.3 Desvio Médio (Standard Deviation) Para uma amostra de n obervações, o Desvio Padrão (SD) será a raiz quadrada positiva da Variância. 2.2.2.4 Quartis, Decis e Percentis Os Quartis dividem um conjunto de obervações ordenados em 4 partes iguais; os Decis, em 10; e, os Percentis, em 100. 2.2.3 Medidas de Forma As medidas de forma permitem a verificação de como um conjunto de dados está se comportando em sua distribuição. Gráficos de distribuição de frequência e histogramas são ferramentas importantes para essa verificação. 2.2.3.1 Assimetria Distribuições em forma de sino são simétricas, já que a média, mediana e moda desse conjunto de dados são iguais. Ou seja, a metade esquerda do histograma é aproximadamente igual à metade direita. Distribuições assimétricas possuem uma concentração de seus dados, à direita ou à esquerda, no histograma. Ou seja, apresentam uma cauda em uma das extremidades. Se a distribuição desses dados estiverem concentrados à direita, são dados com assimetria positiva. Se concentrados à esquerda, assimetria negativa. 2.2.3.1.1 Coeficiente de Assimetria de Pearson \\(A_s=\\frac{3*(\\bar{x} - Md)}{s}\\) 2.2.3.2 Curtose Curtose indica o grau de achatamento de uma distribuição em relação à curva normal. 2.2.3.2.1 Coeficiente de Curtose \\(C=\\frac{Q_3-Q_1}{2*(P_{90} - P_{10})}\\) A curva normal possui C=0,263. Aplicação Para a aplicação, será utilizada a base de dados do Instituto Nacional de Meteorologia (INMET) de precipitação e temperatura na estação meterológica do Mirante de Santana em São Paulo, dos anos de 2014 a 2016. No ano de 2014, São Paulo passou pela pior estiagem deste o ano de 1953. Entre o fim de 2014 e o outono de 2016, a cidade registrou o maior El Niño deste 1950. O El Niño, quando ocorre, causa um aquecimento anômalo das águas superficiais e sub-superficiais do Oceano Pacífico Equatorial, porém, não se comporta de forma constante em relação ao volume de chuvas. Uma das dúvidas do período era se o El niño poderia afetar o regime de chuvas e, assim, aumentar a precipitação em São Paulo. Portanto, iremos aplicar a EDA para verificar essa relação entre o El niño e o volume de chuvas. Para importar a base de dados em .csv, utiliza-se a função read.csv() e insere-se como argumento o diretório: met&lt;- read.csv2(&quot;~/UFABC Beatriz/TG Beatriz Lima/Dados/data1.csv&quot;) met1 &lt;- na.omit(met) # Omitindo os valores faltantes do conjunto de dados É importante lembrar que read.csv() é utilizado quando os valores são separados por vírgula e decimais por ponto; e, read.csv2(), quando são separados por ponto e vírgula e os decimais por vírgula. Para visualizar a tabela importada, basta executar a função View(): View(met1) Para iniciar a exploração dos dados, inicialmente será utilizada a função str() que exibe de forma compacta a estrutura da tabela importada. str(met1) ## &#39;data.frame&#39;: 34 obs. of 5 variables: ## $ Data : chr &quot;2014/01/31&quot; &quot;2014/02/28&quot; &quot;2014/03/31&quot; &quot;2014/04/30&quot; ... ## $ NUMDIAS : int 16 14 18 8 6 5 6 12 8 13 ... ## $ PRECIPITACAOTOTAL: num 223 188.8 212.6 77.2 50.2 ... ## $ TEMPERATURAMEDIA : int 25 25 23 21 19 18 18 20 21 21 ... ## $ ANO : int 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:2] 7 26 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;7&quot; &quot;26&quot; Continuando, será utilizada a função ´summary()´ para apresentar o sumário de estatísticas descritivas (média, mediana, mínimo, máximo, 1º quartil, 3º quartil e valores faltantes (NA)). summary(met1) ## Data NUMDIAS PRECIPITACAOTOTAL TEMPERATURAMEDIA ## Length:34 Min. : 2.00 Min. : 2.40 Min. :15.00 ## Class :character 1st Qu.: 8.00 1st Qu.: 50.35 1st Qu.:18.00 ## Mode :character Median :12.00 Median :105.90 Median :21.00 ## Mean :12.09 Mean :129.05 Mean :20.82 ## 3rd Qu.:16.00 3rd Qu.:201.20 3rd Qu.:23.00 ## Max. :22.00 Max. :327.80 Max. :25.00 ## ANO ## Min. :2014 ## 1st Qu.:2014 ## Median :2015 ## Mean :2015 ## 3rd Qu.:2016 ## Max. :2016 Para continuar explorando os dados, realizou-se um gráfico de linhas a fim de analisar o comportamento da precipitação em relação às datas. year &lt;- met1$Data precip &lt;- met1$PRECIPITACAOTOTAL df &lt;- data.frame(precipitacao=precip, ano=year) library(ggplot2) ggplot(df, aes(x = ano, y = precipitacao)) + geom_line(linetype=&quot;dashed&quot;, color=&quot;blue&quot;, aes(group=1)) + geom_point() A distribuição de frequência da precipitação apresenta assimetria à direita (positiva): ggplot(data = df, aes(x = precip)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Após realizar a sumarização numérica de todos os dados, agora será focado nos dados de interesse: precipitação e ano. Primeiramente, será encontrada a média de precipitação por ano analisado, com um intervalo de confiança de 95% (escore-x da curva normal igual a 1,96). #Média das precipitações por ano library(dplyr) #instalando o pacote para utilizar o operador pipe %&gt;% ## Warning: package &#39;dplyr&#39; was built under R version 4.1.3 ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union tabela_stats &lt;- met1 %&gt;% group_by(ANO) %&gt;% summarise(n_obs = n(), media = mean(PRECIPITACAOTOTAL), desvio_padrao = sd(PRECIPITACAOTOTAL)) %&gt;% mutate(erro = 1.96*desvio_padrao/sqrt(n_obs), limite_superior = media + erro, limite_inferior = media - erro) Com o objetivo de analisar a graficamente os valores de precipitação por ano, será utilizado um gráfico de barras com os erros padrões das amostras. Utiliza-se o erro padrão e não o desvio padrão porque, neste caso, estamos interessados na variabilidade das médias das amostras e não na variabilidade das observações dentro da amostra. #Visualizando a tabela criada com os dados estatísticos View(tabela_stats) #Plotando os valores com seus respectivos erros ggplot (data = tabela_stats, aes(x=ANO, y = media, fill=ANO)) + geom_col() + geom_errorbar(aes(ymin=limite_inferior, ymax=limite_superior)) + ggtitle(&quot;Média das precipitações por ano&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;) É possível analisar que houve um aumento do volume de chuvas no ano de 2015, se comparado com o ano de 2014. O valor médio de precipitação de 2016 é ligeiramente maior que a média de 2014. Porém, não é possível afirmar que os valores de precipitação se devem somente ao El niño, porque também existem diversos fatores, não analisados aqui, que podem influenciar no volume de chuvas. "],["modelos-lineares.html", "Capítulo 3 Modelos lineares 3.1 Covariância 3.2 Correlação 3.3 Regressão linear simples Aplicação", " Capítulo 3 Modelos lineares Resumidamente, modelos lineares são utilizados para resumir relações observadas a partir de dados, no caso, ambientais, em uma linha reta. Em um modelo linear descreve-se o comportamento de uma variável dependente (ou variável resposta, y) como função de uma ou mais variáveis independentes (ou variáveis explicativas, x). 3.1 Covariância A Covariância, denotada \\(\\sigma_{xy}\\), descreve a variação, em relação a média, entre duas variáveis. \\[cov(x,y) = \\frac{\\sum(x_i - \\overline{x})}{n-1}\\] Portanto, é possível saber se ambas variáveis desviam na mesma direção (covariância positiva) ou se desviam em direções opostas (covariância negativa). Caso a covariância entre duas variáveis seja zero, a conclusão é que as variáveis são independentes. 3.2 Correlação A Correlação é útil para medir a relação linear entre duas variáveis x e y, denotada por \\(\\rho_{xy}\\). \\[\\rho_xy = \\frac{cov(x,Y)}{\\sqrt(V(x)V(Y))}\\] Sendo assim, duas variáveis podem estar relacionadas das seguintes formas: Positivamente relacionadas. Ou seja, se x aumenta, y aumenta. E o mesmo ocorre para caso X diminua (Y diminui) - Correlação positiva; Negativamente relacionadas. Ou seja, se x aumenta, y diminui. E o mesmo ocorre para caso x diminua (Y aumenta) - Correlação negativa; Não há relação entre as duas variáveis. Uma forma gráfica de visualizar a correlação das variáveis que apresenta grande utilidade é a partir do Diagrama de Dispersão. O diagrama traz informações importantes porque mostra se a relação entre as variáveis é linear ou não, se existem outliers no conjunto de dados e traz uma ideia de quão forte é o relacionamento entre as variáveis. É importante afirmar que o valor não implica causalidade, mas quantifica a relação entre as variáveis selecionadas. 3.2.1 Coeficiente de Pearson (r) O Coeficiente de Pearson, também chamado de coeficiente de correlação da amostra \\(r_{xy}\\), mede a força da relação linear entre duas variáveis aleatórias x e y. Se duas variáveis relacionarem-se perfeitamente com inclinação positiva, \\(r_{xy}=1\\); com inclinação negativa, \\(r_{xy}=-1\\); se \\(r_{xy}=0\\), não há relação entre as variáveis. De acordo com Filho e Júnior (2009), existem métricas diferentes de acordo com cada autor: Cohen (1998) considera valores entre 0,10 e 0,29 pequenos; entre 0,30 e 0,49, médios; e entre 0,50 e 1, grandes. Dancey e Reidy (2005) considera valores entre 0,10 e 0,30 pequenos; entre 0,40 e 0,60 moderados; e de 0,70 até 1, grandes. O consenso é que quanto mais próximo de 1, maior a força da relação linear entre as variáveis, independente do sinal. 3.3 Regressão linear simples A partir da regressão, é possível obter a relação matemática que descreva a relação entre duas ou mais variáveis. A análise de regressão é uma coleção de ferramentas estatísticas que permite a modelagem e inferência de uma variável dependente (y) com uma ou mais variáveis independentes (x). No caso da regressão linear simples, somente existe uma variável independente; para a regressão linear múltipla, mais de uma. Dessa forma, o formato básico do modelo de regressão linear é: \\[Y = \\beta_0 + \\beta_1X_1 + e_1\\], sendo \\(\\beta_0\\) o coeficiente do intercepto, \\(\\beta_1\\) o coeficiente de inclinação, \\(e_1\\) o erro no ajuste do modelo para a observação y. De acordo com Montgomery &amp; Runger (2021), o modelo de regressão é, na verdade, uma linha de valores médios. Ou seja, a altura da linha de regressão em qualquer valor de x é apenas o valor esperado de Y para aquele x. O coeficiente angular, \\(\\beta_1\\), pode ser interpretado como a mudança na média de Y para uma mudança unitária em x. Além disso, a variabilidade de Y, em um valor particular de x, é determinada pela variância do erro \\(\\sigma^2\\). Portanto, há uma distribuição de valores de Y em cada x de forma que a variância da distribuição é constante em cada x. O erro \\(e_1\\) é estimado pela variabilidade de Y que o modelo criado não consegue explicar, ou seja, o resíduo pode ser quantificado por \\(\\widehat{Y}-Y\\). Os resíduos conseguem indicar se as suposições do modelo foram violadas e, por isso, agora conheceremos as condições necessárias para a aplicação da Regressão Linear. 3.3.1 Condições São assumidas algumas hipóteses sobre os dados de entrada na Regressão Linear: Linearidade: a relação entre X e Y deve ser linear; Homocedasticidade: a variância da variável dependente (Y) deve ser constante para todos os valores das variáveis independentes (X); Normalidade: para um valor fixo de X, Y é uma variável aleatória com distribuição normal. Os erros também devem ser normalmente distribuídos; Dentre diversos testes possíveis, para verificar a não-normalidade dos erros é possível realizar o Teste de Shapiro-Wilk ou um gráfico de Probabilidade Normal com objetivo de verificar visualmente se os dados do modelo apresentam distribuição normal. Independência dos resíduos: como Yi e Yj são valores estatisticamente independentes (falta de correlação), os resíduos também deverão ser independentes; Ausência de outliers influentes: não devem existir outliers que influenciem consideravelmente o modelo; 3.3.2 Coeficiente de Determinação (R²) O Coeficiente de Determinação é utilizado frequentemente pra avaliar a adequação de um modelo de regressão. É definido pelo quadrado do coeficiente de correlação entre X e Y. Quanto mais próximo de 1, maior a quantidade de variabilidade nos dados explicada pelo modelo de regressão. De acordo com Montgomery (2021), o R² pode trazer interpretações errôneas, já que sempre é possível fazer com que R² seja unitário realizando a adição de mais termos ao modelo. Ou seja, R² aumenta se for adicionado uma nova variável ao modelo, mas isso não indica que o modelo esteja mais adequado. Aplicação 3.3.3 Estudo de Caso 1 Para a primeira aplicação, será realizado o exercício 12-14 do livro do autor Montgomery et al (2016) chamado Estatistica Aplicada e Probabilidade para Engenheiros. O enunciado é o seguinte:  options(&quot;install.lock&quot;=FALSE) ## Carregar pacotes que serão usados library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v tibble 3.1.6 v purrr 0.3.4 ## v tidyr 1.2.0 v stringr 1.4.0 ## v readr 2.1.2 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(ggplot2) setwd(&quot;C:/Users/Luiz Arthur/Dropbox/PC/Documents/UFABC Beatriz/TG Beatriz Lima/Dados&quot;) ## Criação do dataframe dados &lt;- read.delim(&quot;Exemplo_12-14_Montgomery.txt&quot;) View(dados) ## Regressão linear mod1 &lt;- lm(Qualidade ~Claridade + Aroma + Corpo + Sabor + Afinacao, dados) summary(mod1) ## ## Call: ## lm(formula = Qualidade ~ Claridade + Aroma + Corpo + Sabor + ## Afinacao, data = dados) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.85552 -0.57448 -0.07092 0.67275 1.68093 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.9969 2.2318 1.791 0.082775 . ## Claridade 2.3395 1.7348 1.349 0.186958 ## Aroma 0.4826 0.2724 1.771 0.086058 . ## Corpo 0.2732 0.3326 0.821 0.417503 ## Sabor 1.1683 0.3045 3.837 0.000552 *** ## Afinacao -0.6840 0.2712 -2.522 0.016833 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.163 on 32 degrees of freedom ## Multiple R-squared: 0.7206, Adjusted R-squared: 0.6769 ## F-statistic: 16.51 on 5 and 32 DF, p-value: 4.703e-08 plot(mod1) Para a análise residual, é necessário investigar se os resíduos refletem as propriedades impostas pelo erro do modelo. Os resíduos não podem apresentar uma tendência e, por isso, eles serão analisado abaixo. Residuals vs Fitted O gráfico mostra a relação entre os resíduos e os valores ajustados. Como a distribuição dos resíduos próxima à linha pontilhada demonsta um bom ajuste do modelo, é possível verificar se resíduos tem padrões não-lineares. No caso do nosso modelo, Normal Q-Q O gráfico mostra se os resíduos são normalmente distribuídos. Mais uma vez, o ideal é que a distribuição dos resíduos acompanhe a linha pontilhada. Pelo gráfico é possível perceber que a distribuição dos resíduos está Scale-Location O gráfico mostra se os resíduos são igualmente distribuídos em relação ao intervalo de preditores (Fitted values).Também é possível checar a homocedasticidade. O ideal, no caso, seria que os resíduos estivessem uniformemente distribuídos ao redor da linha vermelha. Para o caso do nosso modelo, Residuals vs Leverage O gráfico ajuda na visualização de possíveis casos influentes, ou seja, outliers que influenciam na análise de regressão linear. O que quer dizer que, sem o outlier, o resultado da regressão seria diferente. No caso do modelo criado, há possibilidade Cooks distance A Distância de Cook informa o quanto um caso é capaz de influenciar o modelo de regressão. Portanto, o gráfico estima a influência de cada observação no modelo e, novamente, as observações 48, 50 e 51 são extremas. 3.3.4 Estudo de Caso 2 Para o segundo estudo de caso serão utilizados dados de emissões dos gases de efeito estufa (GEE) por mudanças de cobertura da terra da Amazônia Legal disponibilizados pelo INPE (Instituto Nacional de Pesquisas Espaciais). Será representada a relação entre a área desmatada por ano e a emissão de 1ª ordem de \\(CO_2\\) na Amazônia Legal.A estimativa de 1ª ordem supõe que, de modo simplificado, 100% das emissões ocorreram no momento da mudança de uso/cobertura. Um primeiro passo será carregar os dados: options(&quot;install.lock&quot;=FALSE) ## Checando repositório setwd(&quot;C:/Users/Luiz Arthur/Dropbox/PC/Documents/UFABC Beatriz/TG Beatriz Lima/Dados&quot;) ## Carregando base de dados dados0 &lt;- read.csv2(&quot;CO2Amazonia.csv&quot;) dados &lt;- na.omit(dados0) View(dados) data_size= dim(dados) Agora que os dados foram carregados, o segundo passo será entender os dados. Para saber algumas propriedade dos dados carregados, será utilizado o comando head()`, que apresentará uma amostra dos dados, esummary()`, que apresenta as estatísticas básicas dos dados (média, mediana, 1º quartil, etc). head(dados) ## Year D_AreaAcc D_Area DEGRAD_Area X. VR_CO2_1stOrder VR_CO2_2ndOrder ## 1 1960 842754 842754 0 - 411 133 ## 2 1961 1685508 842754 0 - 411 222 ## 3 1962 2528262 842754 0 - 411 276 ## 4 1963 3371016 842754 0 - 411 311 ## 5 1964 4213770 842754 0 - 411 334 ## 6 1965 5056524 842754 0 - 411 350 ## SV_CO2Emission SV_CO2Absorption X..1 DEGRAD_CO2Emission DEGRAD_CO2Absorption ## 1 0 0 - 0 0 ## 2 0 0 - 0 0 ## 3 0 0 - 0 0 ## 4 0 -2 - 0 0 ## 5 0 -4 - 0 0 ## 6 0 -7 - 0 0 ## X..2 NET_1st_Order NET_2nd_Order ## 1 - 411 133 ## 2 - 411 222 ## 3 - 411 276 ## 4 - 409 309 ## 5 - 407 329 ## 6 - 404 342 summary(dados) ## Year D_AreaAcc D_Area DEGRAD_Area ## Min. :1960 Min. : 842754 Min. : 457100 Min. : 0 ## 1st Qu.:1975 1st Qu.:13484064 1st Qu.: 842754 1st Qu.: 0 ## Median :1990 Median :40302326 Median :1103000 Median : 155872 ## Mean :1990 Mean :37464148 Mean :1324505 Mean : 403505 ## 3rd Qu.:2005 3rd Qu.:61076244 3rd Qu.:1822600 3rd Qu.: 155872 ## Max. :2020 Max. :69723152 Max. :2905900 Max. :2741165 ## X. VR_CO2_1stOrder VR_CO2_2ndOrder SV_CO2Emission ## Length:61 Min. : 234.0 Min. : 133.0 Min. : 0.0 ## Class :character 1st Qu.: 411.0 1st Qu.: 381.0 1st Qu.: 7.0 ## Mode :character Median : 541.0 Median : 603.0 Median : 39.0 ## Mean : 653.6 Mean : 616.2 Mean : 48.7 ## 3rd Qu.: 888.0 3rd Qu.: 844.0 3rd Qu.: 83.0 ## Max. :1416.0 Max. :1107.0 Max. :138.0 ## SV_CO2Absorption X..1 DEGRAD_CO2Emission DEGRAD_CO2Absorption ## Min. :-185.00 Length:61 Min. : 0.00 Min. :-245.00 ## 1st Qu.:-143.00 Class :character 1st Qu.: 0.00 1st Qu.: -31.00 ## Median : -81.00 Mode :character Median : 34.00 Median : -18.00 ## Mean : -86.03 Mean : 81.52 Mean : -54.59 ## 3rd Qu.: -28.00 3rd Qu.: 34.00 3rd Qu.: 0.00 ## Max. : 0.00 Max. :691.00 Max. : 0.00 ## X..2 NET_1st_Order NET_2nd_Order ## Length:61 Min. : 108.0 Min. : 133.0 ## Class :character 1st Qu.: 396.0 1st Qu.: 366.0 ## Mode :character Median : 550.0 Median : 667.0 ## Mean : 643.2 Mean : 605.7 ## 3rd Qu.: 880.0 3rd Qu.: 853.0 ## Max. :1380.0 Max. :1053.0 Como iremos analisar a relação entre a área desmatada por ano (D_Area) e a emissão de 1ª ordem de \\(CO_2\\), é importante verificar qual é o comportamento entre esses dados. ## Verificando a relação entre a variável dependente e a variável independente plot(dados$D_Area, dados$VR_CO2_1stOrder) ## Correlação entre as variáveis da base de dados cor.test(dados$VR_CO2_1stOrder,dados$D_Area) ## ## Pearson&#39;s product-moment correlation ## ## data: dados$VR_CO2_1stOrder and dados$D_Area ## t = 152.61, df = 59, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.9978857 0.9992442 ## sample estimates: ## cor ## 0.9987358 A partir desse gráfico, é possível verificar que a relação entre as variáveis é linear e, dessa forma, conforme a área desmatada aumenta, a emissão de \\(CO_2\\) aumenta linearmente. O valor da correlação indica que a relação entre as duas variáveis é forte e positiva, já que 0,9987358 é próximo de 1 e maior que zero. ## Construção do modelo mod &lt;- lm(VR_CO2_1stOrder ~ D_Area, dados, na.action = na.exclude) summary(mod) ## ## Call: ## lm(formula = VR_CO2_1stOrder ~ D_Area, data = dados, na.action = na.exclude) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.178 -12.178 -3.886 1.503 46.689 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.005e+01 4.593e+00 4.364 5.21e-05 *** ## D_Area 4.783e-04 3.134e-06 152.615 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.35 on 59 degrees of freedom ## Multiple R-squared: 0.9975, Adjusted R-squared: 0.9974 ## F-statistic: 2.329e+04 on 1 and 59 DF, p-value: &lt; 2.2e-16 O r² (coeficiente de determinação) do modelo é 0,9975 e, portanto, pode-se interpretar que a variável área explica 99,75% da variação na emissão de \\(CO_2\\) O valor indica que o modelo possui bom ajuste. O p-value do modelo apresenta valor \\(2.2e^{-16}\\) e, assim, apresenta valor menor que o nível de significância (0,05), mostrando que existe baixa probabilidade dos resultados apresentados pelo modelo não possuírem erro amostral. Ou seja, existe alta probabilidade do modelo não ser um bom ajuste. Isso continuará sendo testado a diante. De acordo com Montgomery e Runger (2021), A análise dos resíduos é frequentemente útil na verificação da suposição de que os erros sejam distribuídos de forma aproximadamente normal, com variância constante, assim como na determinação da utilidade dos termos adicionais no modelo. Dessa forma, abaixo será realizada a análise residual. # Análise dos resíduos plot(mod,which = 4) par(mfrow=c(2,2)) plot(mod) ## Teste de normalidade shapiro.test(mod$residuals) ## ## Shapiro-Wilk normality test ## ## data: mod$residuals ## W = 0.75119, p-value = 8.119e-09 Para a análise residual, é necessário investigar se os resíduos refletem as propriedades impostas pelo erro do modelo. Os resíduos não podem apresentar uma tendência e, por isso, eles serão analisado abaixo. Residuals vs Fitted O gráfico mostra a relação entre os resíduos e os valores ajustados. Como a distribuição dos resíduos próxima à linha pontilhada demonsta um bom ajuste do modelo, é possível verificar se resíduos tem padrões não-lineares. No caso do nosso modelo, os resíduos não se apresentam próximos à linha pontilhada. As observações 48, 50 e 51 apresentam grandes valores de resíduos e, por isso, é interessante realizar toda a análise após a remoção dessas observações. Normal Q-Q O gráfico mostra se os resíduos são normalmente distribuídos. Mais uma vez, o ideal é que a distribuição dos resíduos acompanhe a linha pontilhada. Pelo gráfico é possível perceber que a distribuição dos resíduos está diferente da distribuição normal. As observações 48, 50 e 51 apresentam-se extremas novamente. Scale-Location O gráfico mostra se os resíduos são igualmente distribuídos em relação ao intervalo de preditores (Fitted values).Também é possível checar a homocedasticidade. O ideal, no caso, seria que os resíduos estivessem uniformemente distribuídos ao redor da linha vermelha. Para o caso do nosso modelo, demonstra que há heterocedasticidade, ou seja, os resíduos não estão uniformemente distribuídos em relação ao intervalo de preditores. Residuals vs Leverage O gráfico ajuda na visualização de possíveis casos influentes, ou seja, outliers que influenciam na análise de regressão linear. O que quer dizer que, sem o outlier, o resultado da regressão seria diferente. No caso do modelo criado, há possibilidade de existirem outliers influentes. Cooks distance A Distância de Cook informa o quanto um caso é capaz de influenciar o modelo de regressão. Portanto, o gráfico estima a influência de cada observação no modelo e, novamente, as observações 48, 50 e 51 são extremas. CD &lt;- cooks.distance(mod) influentes &lt;- CD[(CD &gt; (3* mean(CD, na.rm=TRUE)))] print(influentes) ## 48 50 51 52 60 61 ## 0.08358518 0.14427282 0.13748969 0.06382214 0.05991051 0.04018312 É possível analisar que existem 6 observações que possuem uma distância de Cook três vezes maior que a média. Além disso, é confirmado que as observações 48, 50 e 51 são extremas. Pelo Teste de Shapiro, é possível verificar que o p-value é menor que 0,05, portanto, o valor não é adequado. O gráfico Normal Q-Q serve como uma contra-prova, também mostrando que os dados não são normalmente distribuídos e, dessa forma, não são adequados. Os resultados dos resíduos indicam no mínimo uma necessidade de aumento do número de dados ou uma amostra mais representativa. Além disso, outra alternativa seria a existência de outliers. Para realizar o teste de outliers, é interessante utilizar os gráficos Boxplot e Histograma. #Encontrando potenciais outliers a partir de gráficos hist(dados$D_Area) hist(dados$VR_CO2_1stOrder) A partir da análise dos resíduos, foi possível inferir que as observações 48, 50 e 51 são outliers influentes. Possivelmente, em relação a área, o outlier está abaixo de 500000 m²; enquanto para a emissão de CO2, acima de 1400 ppm. Para continuar procurando esses possíveis outliers, o pacote outliers pode ser utilizado, já que a função outlier() consegue encontrar o valor mais distante da média das variáveis. #Encontrando os valores com maior diferença da média com o pacote `outliers` library(outliers) ## Warning: package &#39;outliers&#39; was built under R version 4.1.3 outArea &lt;- outlier(dados$D_Area) outCO2 &lt;- outlier(dados$VR_CO2_1stOrder) print(outArea) ## [1] 2905900 print(outCO2) ## [1] 1416 Com esse resultado, analisa-se que existe grande possibilidade de existirem outliers no conjunto de dados, já que as observações 48, 50 e 51 apresentam-se extremas e influentes no modelo de regressão. Além disso, a hipótese de que o resultado dos resíduos indica que seja necessário um maior conjunto de dados também é uma possibilidade. Após todos os testes, por fim, o resultado do modelo de regressão linear simples pode ser visualizado abaixo. #Diagrama de dispersão com o ajuste plot(x = dados$D_Area, y = dados$VR_CO2_1stOrder, xlab = &quot;Área desmatada no ano&quot;, ylab = &quot;Emissão de CO2 de 1a ordem&quot;) abline(mod, col = &quot;blue&quot;) Pelas estatísticas, foi possível analisar que as variáveis relacionam-se de forma positiva e linear, além do modelo apresentar um R² satisfatório. Porém, após a análise dos resíduos, foi possível concluir que o modelo, apesar de ter certas estatísticas boas, não representa de forma adequada a relação entre o desmatamento anual e a emissão de \\(CO_2\\) na Amazônia Legal. Portanto, torna-se importante refazer o modelo, de forma que os outliers influentes (observações 48, 50, 51, 52, 60 e 61) sejam retirados, para verificar se este novo modelo estaria mais adequado para representar a relação entre as variáveis. É isso que faremos: dados_sem_outliers &lt;- dados[-c(48,50,51,52,60,61),] mod2&lt;- lm(VR_CO2_1stOrder ~ D_Area, data=dados_sem_outliers) summary(mod2) ## ## Call: ## lm(formula = VR_CO2_1stOrder ~ D_Area, data = dados_sem_outliers) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.408 -5.408 -2.126 1.689 30.958 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.199e+00 2.461e+00 3.739 0.000455 *** ## D_Area 4.832e-04 1.626e-06 297.158 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.716 on 53 degrees of freedom ## Multiple R-squared: 0.9994, Adjusted R-squared: 0.9994 ## F-statistic: 8.83e+04 on 1 and 53 DF, p-value: &lt; 2.2e-16 plot(mod2) ##Referências Bibliográficas {-} CHAPRA, Steven C. Métodos Numéricos Aplicados com MATLAB® para Engenheiros e Cientistas. Grupo A, 2013. 9788580551778. Disponível em: https://integrada.minhabiblioteca.com.br/#/books/9788580551778/. Acesso em: 21 jun. 2022. Montgomery, Douglas C.; Runger, George C.. Estatística aplicada e probabilidade para engenheiros. tradução e revisão técnica Veronica Calado, Antonio Henrique Monteiro da Fonseca Thomé da Silva · - 7. ed. - Rio de Janeiro : LTC, 2021. SIDHU, Rishi. Laymans Introduction to Linear Regression. Disponível em: https://towardsdatascience.com/laymans-introduction-to-linear-regression-8b334a3dab09 R DOCUMENTATION. shapiro.test(x). Disponível em: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/shapiro.test. FILHO, Dalson Britto Figueiredo; JÚNIOR, José Alexandre da Silva. Desvendando os Mistérios do Coeficiente de Correlação de Pearson (r). Revista Política Hoje vol. 18, n. 1, 2009. Disponível em: https://periodicos.ufpe.br/revistas/politicahoje/article/viewFile/3852/3156. THIEME, Christian. Identifying Outliers in Linear Regression  Cooks Distance. Towards Data Science, 2021. Disponível em: https://towardsdatascience.com/identifying-outliers-in-linear-regression-cooks-distance-9e212e9136a#:~:text=One%20method%20that%20is%20often,the%20ith%20observation%20is%20removed. "],["modelos-lineares-generalizados.html", "Capítulo 4 Modelos Lineares Generalizados 4.1 Testes de hipótese Referências Bibliográficas", " Capítulo 4 Modelos Lineares Generalizados ##Modelos Não Lineares A análise de regressão linear (ARL), conforme apresentado no capítulo anterior, exige suposições que nem sempre são satisfeitas, como normalidade, linearidade, independência e homocedasticidade dos erros. Em situações práticas, isso acaba se tornando uma limitação porque muitos fenômenos geralmente não são lineares. Em diversas aplicações, são envolvidas situações em que há mais de uma variável independente (ou regressora). Portanto, em geral, a variável dependente (Y) pode relacionar-se com k variáveis regressoras: Em modelos mais complexos que o apresentado anteriormente, também é possível aplicar a regressão linear múltipla, a partir de aproximações como, por exemplo, , ainda que a superfície gerada pelo modelo não seja linear. Conforme Montgomery &amp; Runger (2021), qualquer modelo de regressão que seja linear nos parâmetros (os ), independentemente da forma da superfície que ele gere, é um modelo de regressão linear. 4.1 Testes de hipótese Referências Bibliográficas MATTOS, Thalita do Bem. Modelos Não Lineares e suas Aplicações. Universidade Federal de Juiz de Fora, Juiz de Fora, 2013. Disponível em: https://www.ufjf.br/cursoestatistica/files/2014/04/Modelos-N%C3%A3o-Lineares-e-suas-Aplica%C3%A7%C3%B5es.pdf Acesso em: 07/06/2022. Montgomery, Douglas C.; Runger, George C.. Estatística aplicada e probabilidade para engenheiros. tradução e revisão técnica Veronica Calado, Antonio Henrique Monteiro da Fonseca Thomé da Silva · - 7. ed. - Rio de Janeiro : LTC, 2021. "],["análise-de-séries-temporais.html", "Capítulo 5 Análise de séries temporais 5.1 Modelos para séries temporais 5.2 Citations Referências Bibliográficas", " Capítulo 5 Análise de séries temporais Qualquer conjunto de observações ordenadas no tempo são chamadas de Séries Temporais. No caso da Engenharia Ambiental e Urbana, podem ser citados alguns exemplos: valores diários de poluição, valores mensais de temperatura, temperaturas máximas e mínimas diárias ou precipitação atmosférica anual em uma cidade, entre outros (Morettin, 2018). É suposto que, em uma análise de série temporal, há um sistema causal mais ou menos constante, relacionado com o tempo, que exerceu influência sobre os dados no passado e pode continuar a fazê-lo no futuro. Este sistema causal costuma atuar criando padrões não aleatórios que podem ser detectados em um gráfico da série temporal, ou mediante algum outro processo estatístico (REIS, 2022). É importante citar que identificar esses padrões não aleatórios na série temporal de uma variável de interesse é o objetivo da análise. A partir dessa identificação, é possível realizar previsões, orientando tomadas de decisões na área de interesse (REIS, 2022). De acordo com Reis (2022), séries temporais são compostas por até quatro padrões: tendência (T), que é o comportamento de longo prazo da série, que pode ser causada pelo crescimento demográfico, ou mudança gradual de hábitos de consumo, ou qualquer outro aspecto que afete a variável de interesse no longo prazo; variações cíclicas ou ciclos (C), flutuações nos valores da variável com duração superior a um ano, e que se repetem com certa periodicidade, que podem ser resultado de variações da economia como períodos de crescimento ou recessão, ou fenômenos climáticos como o El Niño (que se repete com periodicidade superior a um ano); variações sazonais ou sazonalidade (S), flutuações nos valores da variável com duração inferior a um ano, e que se repetem todos os anos, geralmente em função das estações do ano (ou em função de feriados ou festas populares, ou por exigências legais, como o período para entrega da declaração de Imposto de Renda); se os dados forem registrados anualmente NÃO haverá influência da sazonalidade na série; variações irregulares (I), que são as flutuações inexplicáveis, resultado de fatos fortuitos e inesperados como catástrofes naturais, atentados terroristas como o de 11 de setembro de 2001, decisões intempestivas de governos, etc. É importante citar que uma série temporal nem sempre apresentará todos os padrões citados acima, por mais que o modelo clássico seja o apropriado para analisá-la. Conforme Morettin (2018), existem dois enfoques na análise de séries temporais: 1) análise feita no domínio temporal e os modelos propostos possuem um número finito de parâmetros (paramétricos) e 2) análise feita do domínio de frequências e os modelos propostos são não paramétricos. 5.1 Modelos para séries temporais Footnotes are put inside the square brackets after a caret ^[]. Like this one 1. 5.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2021) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations Referências Bibliográficas BARROS, Anna C.; MATTOS, Daiane Marcolino D.; OLIVEIRA, Ingrid Christyne Luquett D.; et al. Análise de Séries Temporais em R: Curso Introdutório. Grupo GEN, 2017. 9788595154902. Disponível em: https://integrada.minhabiblioteca.com.br/#/books/9788595154902/. Acesso em: 21 jun. 2022. MORETTIN, Pedro A. Análise de Séries Temporais. Editora Blucher, 2018. 9788521213529. Disponível em: https://integrada.minhabiblioteca.com.br/#/books/9788521213529/. Acesso em: 10 jun. 2022. REIS, Marcelo Menezes. Análise de séries temporais. Santa Catarina, UFSC, 2022. Disponível em: https://www.inf.ufsc.br/~marcelo.menezes.reis/Cap4.pdf Acesso em: 10/06/2022. References "],["análise-geoespacial.html", "Capítulo 6 Análise geoespacial 6.1 Dados espaciais e geoespaciais 6.2 Equations 6.3 Theorems and proofs Referências Biliográficas", " Capítulo 6 Análise geoespacial 6.1 Dados espaciais e geoespaciais Dados espaciais são os que utilizam o sistema de coordenadas cartesianas com três (x, y e z) ou mais dimensões. Dados geoespaciais são dados que podem ser mapeados no planeta Terra e relacionadas com outros dados baseados em sistemas de coordenadas geográficas. 6.2 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{6.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (6.1). 6.3 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 6.1. Theorem 6.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. Referências Biliográficas "],["sharing-your-book.html", "Capítulo 7 Sharing your book 7.1 Publishing 7.2 404 pages 7.3 Metadata for sharing", " Capítulo 7 Sharing your book 7.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 7.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If youd like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 7.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your books title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your books source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapters source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["references.html", "References", " References The R Foundation. R: The R Project. Disponível em: https://www.r-project.org/ Wickham, Hadley; Grolemund, Garrett. R for Data Science. Disponível em: https://r4ds.had.co.nz/exploratory-data-analysis.html Montgomery, Douglas C.; Runger, George C.. Estatística aplicada e probabilidade para engenheiros. tradução e revisão técnica Veronica Calado, Antonio Henrique Monteiro da Fonseca Thomé da Silva · - 7. ed. - Rio de Janeiro : LTC, 2021. SIDHU, Rishi. Laymans Introduction to Linear Regression. Disponível em: https://towardsdatascience.com/laymans-introduction-to-linear-regression-8b334a3dab09 DAVIS, Jerry. Introduction to Environmental Data Science. SFSU Institute for Geographic Information Science, 2022. Disponível em: https://bookdown.org/igisc/EnvDataSci/#environmental-data-science. Acesso em: 27 abr. 2022. FILATRO, Andrea C. Data science da educação. [Digite o Local da Editora]: Editora Saraiva, 2020. 9786587958446. Disponível em: https://integrada.minhabiblioteca.com.br/#/books/9786587958446/. Acesso em: 27 abr. 2022. Gibert, Karina; Horsburgh, Jeffery S.; Athanasiadis, Ioannis N.; Holmes, Geoff. Environmental Data Science. Environmental Modelling &amp; Software, 2018. Disponível em: https://reader.elsevier.com/reader/sd/pii/S1364815218301269?token=6B7E02806686B9D1213F7D7D568DD8607AC7EDC45701E1AB2FF569284245D3B9B73444E8F4532FFF767F851CCECF7289&amp;originRegion=us-east-1&amp;originCreation=20220429000236. Acesso em: 28 abr. 2022. R DOCUMENTATION. shapiro.test(x). Disponível em: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/shapiro.test "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
